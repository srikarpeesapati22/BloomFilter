{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloom Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod  \n",
    "\n",
    "# abstract class to represent a set and its insert/search operations\n",
    "class AbstractSet(ABC):\n",
    "    \n",
    "    # constructor\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass           \n",
    "        \n",
    "    # inserts \"element\" in the set\n",
    "    # returns \"True\" after successful insertion, \"False\" if the element is already in the set\n",
    "    # element : str\n",
    "    # inserted : bool\n",
    "    @abstractmethod\n",
    "    def insertElement(self, element):     \n",
    "        inserted = False\n",
    "        return inserted   \n",
    "    \n",
    "    # checks whether \"element\" is in the set\n",
    "    # returns \"True\" if it is, \"False\" otherwise\n",
    "    # element : str\n",
    "    # found : bool\n",
    "    @abstractmethod\n",
    "    def searchElement(self, element):\n",
    "        found = False\n",
    "        return found    \n",
    "    \n",
    "    \n",
    "    \n",
    "# abstract class to represent a synthetic data generator\n",
    "class AbstractTestDataGenerator(ABC):\n",
    "    \n",
    "    # constructor\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass           \n",
    "        \n",
    "    # creates and returns a list of length \"size\" of strings\n",
    "    # size : int\n",
    "    # data : list<str>\n",
    "    @abstractmethod\n",
    "    def generateData(self, size):     \n",
    "        data = [\"\"]*size\n",
    "        return data   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import timeit\n",
    "\n",
    "# generate a random string of given length\n",
    "def generate_random_string(length):\n",
    "\n",
    "    letters = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    return ''.join(random.choice(letters) for _ in range(length))\n",
    "\n",
    "# measure time to insert a elements to a set\n",
    "def insert_time_calc(currentStruct, insert_data):\n",
    "    insert_time = timeit.timeit(lambda: [currentStruct.insertElement(element) for element in insert_data], number=1)\n",
    "    \n",
    "    return insert_time\n",
    "\n",
    "# measure time to search for a elements in a set\n",
    "def search_time_calc(currentStruct, search_data):\n",
    "    search_time = timeit.timeit(lambda: [currentStruct.searchElement(element) for element in search_data], number=1)\n",
    "    \n",
    "    return search_time\n",
    "\n",
    "def false_probability_calculator(n, m, k):\n",
    "    return (1 - (2.718281828459045 ** (-1 * ((k * n) / m)))) ** k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitarray import bitarray\n",
    "        \n",
    "class BloomFilterSet(AbstractSet):\n",
    "    def __init__(self):\n",
    "        self.N = 1_000_000\n",
    "        self.arr = bitarray(self.N)\n",
    "        self.arr.setall(0)\n",
    "        \n",
    "    \n",
    "    # uses mid-square hashing method\n",
    "    def hashFunc1(self, data):\n",
    "        total = 0\n",
    "        count = 1\n",
    "        for ch in data:\n",
    "            total += ord(ch) * count\n",
    "            count *= 10\n",
    "        keyLen = len(str(total))\n",
    "        totalStr = str(total * total)\n",
    "        newKey = totalStr[len(totalStr)//2 - keyLen//2:len(totalStr)//2 + (keyLen - keyLen//2)]\n",
    "        return int(newKey) % self.N\n",
    "\n",
    "    \n",
    "    # uses string folding\n",
    "    def hashFunc2(self, data):\n",
    "        total = 0\n",
    "        count = 1\n",
    "        if len(data) < 4:\n",
    "            for ch in data:\n",
    "                total = ord(ch) * count\n",
    "                count *= 10\n",
    "        else:\n",
    "            times = len(data)//4\n",
    "            rem = len(data) % 4\n",
    "            index = 0\n",
    "            for i in range(1, times + 1):\n",
    "                tempTotal = 0\n",
    "                for j in range(index, i*4):\n",
    "                    tempTotal = ord(data[j]) * count\n",
    "                    count *= 10\n",
    "                total += tempTotal\n",
    "                index += i*4\n",
    "            count = 10\n",
    "            for ch in data[(len(data)-rem):len(data)]:\n",
    "                total += ord(ch) * count\n",
    "                count *= 100\n",
    "        return total % self.N\n",
    "\n",
    "        \n",
    "    def insertElement(self, element):\n",
    "        inserted = False\n",
    "        \n",
    "        hash1 = self.hashFunc1(element)\n",
    "        hash2 = self.hashFunc2(element)\n",
    "        if self.arr[hash1] == 0:\n",
    "            self.arr[hash1] = 1\n",
    "            inserted = True\n",
    "        if self.arr[hash2] == 0:\n",
    "            self.arr[hash2] = 1\n",
    "        if self.arr[hash1] == 0 and self.arr[hash2] == 0:\n",
    "            inserted = True\n",
    "\n",
    "        return inserted\n",
    "    \n",
    "    \n",
    "    def searchElement(self, element):     \n",
    "        found = True\n",
    "\n",
    "        hash1 = self.hashFunc1(element)\n",
    "        hash2 = self.hashFunc2(element)\n",
    "        if self.arr[hash1] != 1:\n",
    "            found = False\n",
    "        elif self.arr[hash2] != 1:\n",
    "            found = False\n",
    "        \n",
    "        return found   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "\n",
    "class TestDataGenerator(AbstractTestDataGenerator):\n",
    "    def __init__(self):        \n",
    "        pass           \n",
    "\n",
    "\n",
    "    # generate a list of length size with random strings (of length up to 100)\n",
    "    # for search and insertion testing\n",
    "    def generateData(self, size, sort=False):\n",
    "        data = []\n",
    "\n",
    "        # generate the list random strings of length 3 to 10\n",
    "        for _ in range(size):\n",
    "            data.append(generate_random_string(random.randint(3, 10)))\n",
    "            \n",
    "        assert len(data) == size\n",
    "        \n",
    "        if sort:\n",
    "            return sorted(data)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloom Filter\n",
      "\tTime to insert 1000000 words: 2.7895474000000036 seconds\n",
      "\tTime to search for 1000000 words: 2.8003597000000013 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "# Testing all 4 data structures on synthetic data\n",
    "\n",
    "max_size = 1_000_000\n",
    "\n",
    "insert_size = max_size\n",
    "search_size = max_size\n",
    "\n",
    "# synthetic data generator\n",
    "syn_test = TestDataGenerator()\n",
    "\n",
    "# generate synthetic data to insert\n",
    "insert_data = syn_test.generateData(insert_size)\n",
    "\n",
    "# generate data to search (half of insert_data and half of generated data - all shuffled)\n",
    "search_data = insert_data[:(len(insert_data) // 2)] + syn_test.generateData(search_size // 2)\n",
    "random.shuffle(search_data)\n",
    "\n",
    "# ensure the size of insert and search data matches\n",
    "assert len(insert_data) == max_size\n",
    "assert len(search_data) == max_size\n",
    "currentStruct = BloomFilterSet()\n",
    "print(\"Bloom Filter\")\n",
    "insert_time = timeit.timeit(lambda: [currentStruct.insertElement(word) for word in insert_data], number=1)\n",
    "search_time = timeit.timeit(lambda: [currentStruct.searchElement(word) for word in search_data], number=1) \n",
    "print(f\"\\tTime to insert {insert_size} words: {insert_time} seconds\")\n",
    "print(f\"\\tTime to search for {search_size} words: {search_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# measuring time to insert/search 10 000 elements every 100 000 elements\n",
    "STEP = 100_000\n",
    "STEP_INSERT_SEARCH = 10_000\n",
    "\n",
    "\n",
    "# numbers of elements in the set at times of measurements\n",
    "nums_of_elements_insert = []\n",
    "nums_of_elements_search = []\n",
    "bloom_insert_times = []\n",
    "bloom_search_times = []\n",
    "\n",
    "\n",
    "# synthetic data generator\n",
    "tdg = TestDataGenerator()\n",
    "bloomSet = BloomFilterSet()\n",
    "\n",
    "for i in range(0, 101):\n",
    "    # current number of elements in the set before insertion and search\n",
    "    nums_of_elements_insert.append(i * STEP)\n",
    "    nums_of_elements_search.append(i * STEP + STEP_INSERT_SEARCH)\n",
    "\n",
    "    # generate random elements to insert\n",
    "    insert_elements = tdg.generateData(STEP_INSERT_SEARCH)\n",
    "    assert len(insert_elements) == STEP_INSERT_SEARCH\n",
    "    \n",
    "    # measure time to insert random elements into the set\n",
    "    bloom_insert_times.append(insert_time_calc(bloomSet, insert_elements))\n",
    "\n",
    "    # generate elements to search (half that are in the set for sure, half random)\n",
    "    search_elements = insert_elements[:(STEP_INSERT_SEARCH//2)] + tdg.generateData(STEP_INSERT_SEARCH//2)\n",
    "    random.shuffle(search_elements)\n",
    "    assert len(search_elements) == STEP_INSERT_SEARCH\n",
    "    \n",
    "    # measure time to search for the elements in the set\n",
    "    bloom_search_times.append(search_time_calc(bloomSet, search_elements))\n",
    "        \n",
    "    # generate the rest of random elements to be inserted in the step\n",
    "    random_elements = tdg.generateData(STEP - STEP_INSERT_SEARCH)\n",
    "    \n",
    "    # insert it into every ds (no time measuring - using insert_time_calc temporary)\n",
    "    for element in random_elements:\n",
    "        bloomSet.insertElement(element)\n",
    "\n",
    "# plot search graph\n",
    "plt.plot(nums_of_elements_search, bloom_search_times, label=\"Bloom\")\n",
    "\n",
    "plt.xlabel(\"Number of elements in the set\")\n",
    "plt.ylabel(\"Time to search for \" + str(STEP_INSERT_SEARCH) + \" elements (sec)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot insert graph\n",
    "plt.plot(nums_of_elements_insert, bloom_insert_times, label=\"Bloom\")\n",
    "\n",
    "plt.xlabel(\"Number of elements in the set\")\n",
    "plt.ylabel(\"Time to insert \" + str(STEP_INSERT_SEARCH) + \" elements (sec)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
